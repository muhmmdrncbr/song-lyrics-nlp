# 🎶 Song Lyrics NLP Project

Bu proje, İngilizce şarkı sözleri üzerinden doğal dil işleme (NLP) yöntemleri kullanarak **öneri sistemleri** geliştirmeyi ve **TF-IDF** ile **Word2Vec** tekniklerinin performansını karşılaştırmayı amaçlamaktadır. Metin verileri temizlendikten sonra vektörleştirilerek anlamsal benzerlik analizleri yapılmıştır.

---

## 📊 Veri Seti Hakkında

Bu projede kullanılan ham veri, farklı tür ve sanatçılardan derlenmiş **55.000+** şarkı sözü satırı içerir. Temizleme ve ön işleme sürecinden geçirilerek iki ayrı versiyon oluşturulmuştur:

| Özellik           | Açıklama                                                               |
| ----------------- | ---------------------------------------------------------------------- |
| 🎵 Satır Sayısı   | Yaklaşık **55.650** şarkı sözü satırı                                  |
| 📂 İçerik         | Her satırda bir şarkı sözü; `artist`, `song`, `cleaned_text` sütunları |
| 📄 Dosya Formatı  | CSV (`.csv`)                                                           |
| ✨ Versiyonlama    | `cleaned_lemmatized.csv` ve `cleaned_stemmed.csv`                      |
| 🛠️ Ön İşleme     | Noktalama, rakam, özel karakter temizliği + lemmatization & stemming   |
| 🔍 Kullanım Amacı | TF-IDF, Word2Vec (embedding) analizleri                                |

> **Not:** Veri seti kamuya açık değildir; akademik çalışma amacıyla sınırlı kullanılmıştır.

---

## ⚙️ Kurulum

Aşağıdaki adımları izleyerek projeyi çalıştırabilirsiniz:

1. **Repoyu klonlayın**

   ```bash
   git clone https://github.com/muhmmdrncbr/song-lyrics-nlp.git
   cd song-lyrics-nlp
   ```
2. **Sanal ortam oluşturun ve aktif edin**

   ```bash
   python -m venv venv
   source venv/bin/activate   # macOS/Linux
   venv\\Scripts\\activate # Windows
   ```
3. **Gerekli paketleri yükleyin**

   ```bash
   pip install -r requirements.txt
   ```

---

## ▶️ Nasıl Çalıştırılır

1. **Jupyter Notebook** sunucusunu başlatın:

   ```bash
   jupyter notebook
   ```
2. `notebooks/final2_odev_song_recommender.ipynb` dosyasını açın.
3. Hücreleri sırayla çalıştırarak analizleri ve sonuçları inceleyin.
4. **Sonuçlar ve Grafikler** otomatik olarak `results/` ve `figures/` klasörlerine kaydedilecektir.

> **Öneri:** Tek satırda HTML raporu oluşturmak için:
>
> ```bash
> jupyter nbconvert --to html --execute notebooks/final2_odev_song_recommender.ipynb --output figures/rapor.html
> ```

---

## 📁 Proje Klasör Yapısı

```text
├── data/                 # Temizlenmiş CSV dosyaları
├── models/               # Word2Vec .model dosyaları
├── results/              # Benzerlik sonuçları (CSV)
├── requirements.txt      # Bağımlılıklar
└── README2.md             # Proje dokümantasyonu
```

---

## 📈 Sonuçlar ve Değerlendirme

Bu bölümde, proje süresince elde edilen başlıca bulgular özetlenmekte ve modeller arası performans karşılaştırılması sunulmaktadır.

### 🔹 TF-IDF Modelleri

* **Ortalama Cosine Similarity (Top‑5)**: 0.56 – 0.66 aralığında yoğunlaştı.
* **Ortalama Semantic Score**: 1.5 – 2.0 aralığında, anlamsal yeterliliğin düşük olduğunu gösterdi.
* **Jaccard Tutarlılığı**: Lemmatized ve Stemmed versiyonlar arasında J ≈ 0.67; model varyasyonları arasında yüksek örtüşme, ancak bağlamsal anlam kaybı.
* **Genel Değerlendirme**: TF-IDF, hızlı ve düşük kaynak tüketimli ortamlarda temel kelime benzerlikleri için uygun. Ancak, içerik derinliği ve anlamsal tutarlılık gerektiren uygulamalarda yetersiz kalmaktadır.

### 🔹 Word2Vec Modelleri

* **En Yüksek Cosine Similarity**: Skip‑Gram + HS (w=10) modelinde 0.96’nın üzerine çıktı.
* **Ortalama Semantic Score**: 4.2 – 4.8 aralığında yüksek anlamsal doğruluk.
* **Parametre Etkisi**:

  * **Skip‑Gram (sg=1)** modelleri, CBOW’a göre %20–30 daha yüksek semantic skorlar sağladı.
  * **Hierarchical Softmax (hs=1)** ile özellikle Skip‑Gram kombinasyonu, öneri kalitesini belirgin biçimde artırdı.
  * **Pencere Boyutu (w=5 vs w=10)**, küçük boyutta dahi tutarlı bağlam öğrenmeyi sürdürdü.
* **Jaccard Tutarlılığı**:

  * Aynı aile içi varyasyonlarda J değerleri 0.43 – 0.67 aralığında. Parametre değişimi öneri listesini önemli ölçüde çeşitlendirdi.
  * TF‑IDF modelleriyle örtüşme neredeyse sıfır; tamamen farklı öneri setleri.

### 🔹 Karşılaştırmalı Analiz

| Model              | Avg Similarity | Avg Semantic Score |      Jaccard (En yakın)     |
| ------------------ | :------------: | :----------------: | :-------------------------: |
| TF-IDF Lemmatized  |      0.61      |         1.7        |       vs Stemmed: 0.67      |
| TF-IDF Stemmed     |      0.63      |         1.8        |     vs Lemmatized: 0.67     |
| w2v\_sg1\_hs1\_w10 |      0.96      |         4.8        | vs w2v\_sg1\_hs0\_w10: 0.60 |
| w2v\_sg1\_hs0\_w5  |      0.95      |         4.6        |  vs w2v\_sg1\_hs1\_w5: 0.57 |

### 🔹 Öneriler

1. **Yüksek Doğruluk Gerektiren Uygulamalar**: Skip‑Gram + HS (w=10) Word2Vec modeli tercih edilmeli.
2. **Kaynak ve Hız Öncelikli Senaryolar**: TF‑IDF ile hızlı ön filtreleme, ardından Word2Vec tabanlı derinlemesine analiz önerilir.
3. **Hibrit Yaklaşımlar**: TF‑IDF ile olası adayları daraltıp, Word2Vec ile anlamsal seçki yapmak performansı ve doğruluğu birlikte optimize eder.

---

## 📚 Kaynakça


* Natural Language Toolkit (NLTK) Documentation: [https://www.nltk.org/](https://www.nltk.org/)
  → Metin işleme, tokenization, stopword, lemmatization ve stemming işlemleri için kullanıldı.
* Gensim Documentation: [https://radimrehurek.com/gensim/](https://radimrehurek.com/gensim/)
  → Word2Vec algoritmasının uygulanması ve eğitiminde kullanıldı.
* Scikit-learn Documentation: [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)
  → TF-IDF vektörleştirme, veri ön işleme ve modelleme için yararlanıldı.
* Pandas Documentation: [https://pandas.pydata.org/](https://pandas.pydata.org/)
  → CSV dosyalarının okunması, veri çerçevesi işlemleri ve temizleme süreçlerinde kullanıldı.
* Regex Reference (Python re module): [https://docs.python.org/3/library/re.html](https://docs.python.org/3/library/re.html)
  → Metinlerden özel karakterleri temizlemek ve desen eşleştirme işlemleri için kullanıldı.
* Proje Reposu (GitHub): [https://github.com/muhmmdrncbr/song-lyrics-nlp](https://github.com/muhmmdrncbr/song-lyrics-nlp)
  → Tüm proje kodlarına ve temiz veri dosyalarına buradan ulaşılabilir.
* DBS Gümüşhane Üniversitesi: [https://dbs.gumushane.edu.tr/course/view.php?id=20035](https://dbs.gumushane.edu.tr/course/view.php?id=20035)
  → Gerekli bilgiler için dersteki PDF’ler kullanıldı.
