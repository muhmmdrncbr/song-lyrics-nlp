# Song Recommender System

Bu proje, Ä°ngilizce ÅŸarkÄ± sÃ¶zleri Ã¼zerinden bir iÃ§erik tabanlÄ± Ã¶neri sistemi (TF-IDF ve Word2Vec) geliÅŸtirmeyi ve farklÄ± yÃ¶ntemlerin Ã¶neri kalitesini karÅŸÄ±laÅŸtÄ±rmayÄ± amaÃ§lar.

## ğŸ“‹ Ã–n KoÅŸullar ve BaÄŸÄ±mlÄ±lÄ±klar

* **Python 3.8+**
* Tercihe baÄŸlÄ± olarak **conda** veya **venv** ile izole bir sanal ortam

Gerekli Python paketleri (en gÃ¼ncel sÃ¼rÃ¼mler):

```
pip install pandas numpy scikit-learn gensim nltk matplotlib seaborn jupyter
```

> **Alternatif olarak** bir `requirements.txt` dosyasÄ± oluÅŸturup:
>
> ```bash
> pip install -r requirements.txt
> ```
>
> komutuyla tÃ¼m baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyebilirsiniz.

## âš™ï¸ Kurulum AdÄ±mlarÄ±

1. Depoyu klonlayÄ±n:

   ```bash
   git clone https://github.com/muhmmdrncbr/song-lyrics-nlp
   cd sarki-onerici
   ```
2. Sanal ortamÄ± oluÅŸturun ve aktif edin:

   ```bash
   python -m venv venv
   source venv/bin/activate    # macOS/Linux
   venv\\Scripts\\activate   # Windows
   ```
3. BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:

   ```bash
   pip install -r requirements.txt
   ```
4. Veri ve model dosyalarÄ±nÄ± `data/` ve `models/` klasÃ¶rlerine yerleÅŸtirin:

   * `data/cleaned_lemmatized.csv`, `data/cleaned_stemmed.csv`
   * `data/tfidf_lemmatized.csv`, `data/tfidf_stemmed.csv`
   * `models/word2vec_*.model` (16 adet)

## â–¶ï¸ NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r

1. Jupyter Notebook sunucusunu baÅŸlatÄ±n:

   ```bash
   jupyter notebook
   ```
2. `notebooks/final2_odev_song_recommender.ipynb` dosyasÄ±nÄ± aÃ§Ä±n.
3. HÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rarak adÄ±m adÄ±m Ã¶neri sistemini ve analizleri inceleyin.




## ğŸ“ˆ SonuÃ§lar ve DeÄŸerlendirme

Bu bÃ¶lÃ¼mde, proje sÃ¼resince elde edilen baÅŸlÄ±ca bulgular Ã¶zetlenmekte ve modeller arasÄ± performans karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ± sunulmaktadÄ±r.

### ğŸ”¹ TF-IDF Modelleri

* **Ortalama Cosine Similarity (Topâ€‘5)**: 0.56 â€“ 0.66 aralÄ±ÄŸÄ±nda yoÄŸunlaÅŸtÄ±.
* **Ortalama Semantic Score**: 1.5 â€“ 2.0 aralÄ±ÄŸÄ±nda, anlamsal yeterliliÄŸin dÃ¼ÅŸÃ¼k olduÄŸunu gÃ¶sterdi.
* **Jaccard TutarlÄ±lÄ±ÄŸÄ±**: Lemmatized ve Stemmed versiyonlar arasÄ±nda J â‰ˆ 0.67; model varyasyonlarÄ± arasÄ±nda yÃ¼ksek Ã¶rtÃ¼ÅŸme, ancak baÄŸlamsal anlam kaybÄ±.
* **Genel DeÄŸerlendirme**: TF-IDF, hÄ±zlÄ± ve dÃ¼ÅŸÃ¼k kaynak tÃ¼ketimli ortamlarda temel kelime benzerlikleri iÃ§in uygun. Ancak, iÃ§erik derinliÄŸi ve anlamsal tutarlÄ±lÄ±k gerektiren uygulamalarda yetersiz kalmaktadÄ±r.

### ğŸ”¹ Word2Vec Modelleri

* **En YÃ¼ksek Cosine Similarity**: Skipâ€‘Gram + HS (w=10) modelinde 0.96â€™nÄ±n Ã¼zerine Ã§Ä±ktÄ±.
* **Ortalama Semantic Score**: 4.2 â€“ 4.8 aralÄ±ÄŸÄ±nda yÃ¼ksek anlamsal doÄŸruluk.
* **Parametre Etkisi**:

  * **Skipâ€‘Gram (sg=1)** modelleri, CBOWâ€™a gÃ¶re %20â€“30 daha yÃ¼ksek semantic skorlar saÄŸladÄ±.
  * **Hierarchical Softmax (hs=1)** ile Ã¶zellikle Skipâ€‘Gram kombinasyonu, Ã¶neri kalitesini belirgin biÃ§imde artÄ±rdÄ±.
  * **Pencere Boyutu (w=5 vs w=10)**, kÃ¼Ã§Ã¼k boyutta dahi tutarlÄ± baÄŸlam Ã¶ÄŸrenmeyi sÃ¼rdÃ¼rdÃ¼.
* **Jaccard TutarlÄ±lÄ±ÄŸÄ±**:

  * AynÄ± aile iÃ§i varyasyonlarda J deÄŸerleri 0.43 â€“ 0.67 aralÄ±ÄŸÄ±nda. Parametre deÄŸiÅŸimi Ã¶neri listesini Ã¶nemli Ã¶lÃ§Ã¼de Ã§eÅŸitlendirdi.
  * TFâ€‘IDF modelleriyle Ã¶rtÃ¼ÅŸme neredeyse sÄ±fÄ±r; tamamen farklÄ± Ã¶neri setleri.

### ğŸ”¹ KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz

| Model              | Avg Similarity | Avg Semantic Score |      Jaccard (En yakÄ±n)     |
| ------------------ | :------------: | :----------------: | :-------------------------: |
| TF-IDF Lemmatized  |      0.61      |         1.7        |       vs Stemmed: 0.67      |
| TF-IDF Stemmed     |      0.63      |         1.8        |     vs Lemmatized: 0.67     |
| w2v\_sg1\_hs1\_w10 |      0.96      |         4.8        | vs w2v\_sg1\_hs0\_w10: 0.60 |
| w2v\_sg1\_hs0\_w5  |      0.95      |         4.6        |  vs w2v\_sg1\_hs1\_w5: 0.57 |

### ğŸ”¹ Ã–neriler

1. **YÃ¼ksek DoÄŸruluk Gerektiren Uygulamalar**: Skipâ€‘Gram + HS (w=10) Word2Vec modeli tercih edilmeli.
2. **Kaynak ve HÄ±z Ã–ncelikli Senaryolar**: TFâ€‘IDF ile hÄ±zlÄ± Ã¶n filtreleme, ardÄ±ndan Word2Vec tabanlÄ± derinlemesine analiz Ã¶nerilir.
3. **Hibrit YaklaÅŸÄ±mlar**: TFâ€‘IDF ile olasÄ± adaylarÄ± daraltÄ±p, Word2Vec ile anlamsal seÃ§ki yapmak performansÄ± ve doÄŸruluÄŸu birlikte optimize eder.

### ğŸ“‚ Kaynak KonumlarÄ±

* **CSV SonuÃ§larÄ±**: `results/tfidf_top5.csv`, `results/word2vec_top5.csv`


## ğŸ“š Referanslar

â€¢  Natural Language Toolkit (NLTK) Documentation 
https://www.nltk.org/ 
â†’ Metin iÅŸleme, tokenization, stopword, lemmatization ve stemming iÅŸlemleri iÃ§in kullanÄ±ldÄ±. 
â€¢  Gensim Documentation 
https://radimrehurek.com/gensim/ 
â†’ Word2Vec algoritmasÄ±nÄ±n uygulanmasÄ± ve eÄŸitiminde kullanÄ±ldÄ±. 
â€¢  Scikit-learn Documentation 
https://scikit-learn.org/stable/ 
â†’ TF-IDF vektÃ¶rleÅŸtirme, veri Ã¶n iÅŸleme ve modelleme iÃ§in yararlanÄ±ldÄ±. 
â€¢  Pandas Documentation 
https://pandas.pydata.org/ 
â†’ CSV dosyalarÄ±nÄ±n okunmasÄ±, veri Ã§erÃ§evesi iÅŸlemleri ve temizleme sÃ¼reÃ§lerinde kullanÄ±ldÄ±. 
â€¢  Regex Reference (Python re module) 
https://docs.python.org/3/library/re.html 
â†’ Metinlerden Ã¶zel karakterleri temizlemek ve desen eÅŸleÅŸtirme iÅŸlemleri iÃ§in kullanÄ±ldÄ±. 
â€¢  Proje Reposu (GitHub) 
https://github.com/muhmmdrncbr/song-lyrics-nlp 
â†’ TÃ¼m proje kodlarÄ±na ve temiz veri dosyalarÄ±na buradan ulaÅŸÄ±labilir. 
â€¢DBS GÃ¼mÃ¼ÅŸhane Ãœniversitesi  
https://dbs.gumushane.edu.tr/course/view.php?id=20035 
â†’Gerekli bilgiler iÃ§in dersteki  pdfler kullanÄ±ldÄ±
