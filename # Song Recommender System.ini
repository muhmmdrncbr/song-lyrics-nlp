# ğŸ¶ Song Lyrics NLP Project

Bu proje, Ä°ngilizce ÅŸarkÄ± sÃ¶zleri Ã¼zerinden doÄŸal dil iÅŸleme (NLP) yÃ¶ntemleri kullanarak **Ã¶neri sistemleri** geliÅŸtirmeyi ve **TF-IDF** ile **Word2Vec** tekniklerinin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmayÄ± amaÃ§lamaktadÄ±r. Metin verileri temizlendikten sonra vektÃ¶rleÅŸtirilerek anlamsal benzerlik analizleri yapÄ±lmÄ±ÅŸtÄ±r.

---

## ğŸ“Š Veri Seti HakkÄ±nda

Bu projede kullanÄ±lan ham veri, farklÄ± tÃ¼r ve sanatÃ§Ä±lardan derlenmiÅŸ **55.000+** ÅŸarkÄ± sÃ¶zÃ¼ satÄ±rÄ± iÃ§erir. Temizleme ve Ã¶n iÅŸleme sÃ¼recinden geÃ§irilerek iki ayrÄ± versiyon oluÅŸturulmuÅŸtur:

| Ã–zellik           | AÃ§Ä±klama                                                               |
| ----------------- | ---------------------------------------------------------------------- |
| ğŸµ SatÄ±r SayÄ±sÄ±   | YaklaÅŸÄ±k **55.650** ÅŸarkÄ± sÃ¶zÃ¼ satÄ±rÄ±                                  |
| ğŸ“‚ Ä°Ã§erik         | Her satÄ±rda bir ÅŸarkÄ± sÃ¶zÃ¼; `artist`, `song`, `cleaned_text` sÃ¼tunlarÄ± |
| ğŸ“„ Dosya FormatÄ±  | CSV (`.csv`)                                                           |
| âœ¨ Versiyonlama    | `cleaned_lemmatized.csv` ve `cleaned_stemmed.csv`                      |
| ğŸ› ï¸ Ã–n Ä°ÅŸleme     | Noktalama, rakam, Ã¶zel karakter temizliÄŸi + lemmatization & stemming   |
| ğŸ” KullanÄ±m AmacÄ± | TF-IDF, Word2Vec (embedding) analizleri                                |

> **Not:** Veri seti kamuya aÃ§Ä±k deÄŸildir; akademik Ã§alÄ±ÅŸma amacÄ±yla sÄ±nÄ±rlÄ± kullanÄ±lmÄ±ÅŸtÄ±r.

---

## âš™ï¸ Kurulum

AÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyerek projeyi Ã§alÄ±ÅŸtÄ±rabilirsiniz:

1. **Repoyu klonlayÄ±n**

   ```bash
   git clone https://github.com/muhmmdrncbr/song-lyrics-nlp.git
   cd song-lyrics-nlp
   ```
2. **Sanal ortam oluÅŸturun ve aktif edin**

   ```bash
   python -m venv venv
   source venv/bin/activate   # macOS/Linux
   venv\\Scripts\\activate # Windows
   ```
3. **Gerekli paketleri yÃ¼kleyin**

   ```bash
   pip install -r requirements.txt
   ```

---

## â–¶ï¸ NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r

1. **Jupyter Notebook** sunucusunu baÅŸlatÄ±n:

   ```bash
   jupyter notebook
   ```
2. `notebooks/final2_odev_song_recommender.ipynb` dosyasÄ±nÄ± aÃ§Ä±n.
3. HÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rarak analizleri ve sonuÃ§larÄ± inceleyin.
4. **SonuÃ§lar ve Grafikler** otomatik olarak `results/` ve `figures/` klasÃ¶rlerine kaydedilecektir.

> **Ã–neri:** Tek satÄ±rda HTML raporu oluÅŸturmak iÃ§in:
>
> ```bash
> jupyter nbconvert --to html --execute notebooks/final2_odev_song_recommender.ipynb --output figures/rapor.html
> ```

---

## ğŸ“ Proje KlasÃ¶r YapÄ±sÄ±

```text
â”œâ”€â”€ data/                 # TemizlenmiÅŸ CSV dosyalarÄ±
â”œâ”€â”€ models/               # Word2Vec .model dosyalarÄ±
â”œâ”€â”€ results/              # Benzerlik sonuÃ§larÄ± (CSV)
â”œâ”€â”€ requirements.txt      # BaÄŸÄ±mlÄ±lÄ±klar
â””â”€â”€ README2.md             # Proje dokÃ¼mantasyonu
```

---

## ğŸ“ˆ SonuÃ§lar ve DeÄŸerlendirme

Bu bÃ¶lÃ¼mde, proje sÃ¼resince elde edilen baÅŸlÄ±ca bulgular Ã¶zetlenmekte ve modeller arasÄ± performans karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ± sunulmaktadÄ±r.

### ğŸ”¹ TF-IDF Modelleri

* **Ortalama Cosine Similarity (Topâ€‘5)**: 0.56 â€“ 0.66 aralÄ±ÄŸÄ±nda yoÄŸunlaÅŸtÄ±.
* **Ortalama Semantic Score**: 1.5 â€“ 2.0 aralÄ±ÄŸÄ±nda, anlamsal yeterliliÄŸin dÃ¼ÅŸÃ¼k olduÄŸunu gÃ¶sterdi.
* **Jaccard TutarlÄ±lÄ±ÄŸÄ±**: Lemmatized ve Stemmed versiyonlar arasÄ±nda JÂ â‰ˆÂ 0.67; model varyasyonlarÄ± arasÄ±nda yÃ¼ksek Ã¶rtÃ¼ÅŸme, ancak baÄŸlamsal anlam kaybÄ±.
* **Genel DeÄŸerlendirme**: TF-IDF, hÄ±zlÄ± ve dÃ¼ÅŸÃ¼k kaynak tÃ¼ketimli ortamlarda temel kelime benzerlikleri iÃ§in uygun. Ancak, iÃ§erik derinliÄŸi ve anlamsal tutarlÄ±lÄ±k gerektiren uygulamalarda yetersiz kalmaktadÄ±r.

### ğŸ”¹ Word2Vec Modelleri

* **En YÃ¼ksek Cosine Similarity**: Skipâ€‘Gram + HS (w=10) modelinde 0.96â€™nÄ±n Ã¼zerine Ã§Ä±ktÄ±.
* **Ortalama Semantic Score**: 4.2 â€“ 4.8 aralÄ±ÄŸÄ±nda yÃ¼ksek anlamsal doÄŸruluk.
* **Parametre Etkisi**:

  * **Skipâ€‘Gram (sg=1)** modelleri, CBOWâ€™a gÃ¶re %20â€“30 daha yÃ¼ksek semantic skorlar saÄŸladÄ±.
  * **Hierarchical Softmax (hs=1)** ile Ã¶zellikle Skipâ€‘Gram kombinasyonu, Ã¶neri kalitesini belirgin biÃ§imde artÄ±rdÄ±.
  * **Pencere Boyutu (w=5 vs w=10)**, kÃ¼Ã§Ã¼k boyutta dahi tutarlÄ± baÄŸlam Ã¶ÄŸrenmeyi sÃ¼rdÃ¼rdÃ¼.
* **Jaccard TutarlÄ±lÄ±ÄŸÄ±**:

  * AynÄ± aile iÃ§i varyasyonlarda J deÄŸerleri 0.43 â€“ 0.67 aralÄ±ÄŸÄ±nda. Parametre deÄŸiÅŸimi Ã¶neri listesini Ã¶nemli Ã¶lÃ§Ã¼de Ã§eÅŸitlendirdi.
  * TFâ€‘IDF modelleriyle Ã¶rtÃ¼ÅŸme neredeyse sÄ±fÄ±r; tamamen farklÄ± Ã¶neri setleri.

### ğŸ”¹ KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz

| Model              | Avg Similarity | Avg Semantic Score |      Jaccard (En yakÄ±n)     |
| ------------------ | :------------: | :----------------: | :-------------------------: |
| TF-IDF Lemmatized  |      0.61      |         1.7        |       vs Stemmed: 0.67      |
| TF-IDF Stemmed     |      0.63      |         1.8        |     vs Lemmatized: 0.67     |
| w2v\_sg1\_hs1\_w10 |      0.96      |         4.8        | vs w2v\_sg1\_hs0\_w10: 0.60 |
| w2v\_sg1\_hs0\_w5  |      0.95      |         4.6        |  vs w2v\_sg1\_hs1\_w5: 0.57 |

### ğŸ”¹ Ã–neriler

1. **YÃ¼ksek DoÄŸruluk Gerektiren Uygulamalar**: Skipâ€‘Gram + HS (w=10) Word2Vec modeli tercih edilmeli.
2. **Kaynak ve HÄ±z Ã–ncelikli Senaryolar**: TFâ€‘IDF ile hÄ±zlÄ± Ã¶n filtreleme, ardÄ±ndan Word2Vec tabanlÄ± derinlemesine analiz Ã¶nerilir.
3. **Hibrit YaklaÅŸÄ±mlar**: TFâ€‘IDF ile olasÄ± adaylarÄ± daraltÄ±p, Word2Vec ile anlamsal seÃ§ki yapmak performansÄ± ve doÄŸruluÄŸu birlikte optimize eder.

---

## ğŸ“š KaynakÃ§a


* Natural Language Toolkit (NLTK) Documentation: [https://www.nltk.org/](https://www.nltk.org/)
  â†’ Metin iÅŸleme, tokenization, stopword, lemmatization ve stemming iÅŸlemleri iÃ§in kullanÄ±ldÄ±.
* Gensim Documentation: [https://radimrehurek.com/gensim/](https://radimrehurek.com/gensim/)
  â†’ Word2Vec algoritmasÄ±nÄ±n uygulanmasÄ± ve eÄŸitiminde kullanÄ±ldÄ±.
* Scikit-learn Documentation: [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)
  â†’ TF-IDF vektÃ¶rleÅŸtirme, veri Ã¶n iÅŸleme ve modelleme iÃ§in yararlanÄ±ldÄ±.
* Pandas Documentation: [https://pandas.pydata.org/](https://pandas.pydata.org/)
  â†’ CSV dosyalarÄ±nÄ±n okunmasÄ±, veri Ã§erÃ§evesi iÅŸlemleri ve temizleme sÃ¼reÃ§lerinde kullanÄ±ldÄ±.
* Regex Reference (Python re module): [https://docs.python.org/3/library/re.html](https://docs.python.org/3/library/re.html)
  â†’ Metinlerden Ã¶zel karakterleri temizlemek ve desen eÅŸleÅŸtirme iÅŸlemleri iÃ§in kullanÄ±ldÄ±.
* Proje Reposu (GitHub): [https://github.com/muhmmdrncbr/song-lyrics-nlp](https://github.com/muhmmdrncbr/song-lyrics-nlp)
  â†’ TÃ¼m proje kodlarÄ±na ve temiz veri dosyalarÄ±na buradan ulaÅŸÄ±labilir.
* DBS GÃ¼mÃ¼ÅŸhane Ãœniversitesi: [https://dbs.gumushane.edu.tr/course/view.php?id=20035](https://dbs.gumushane.edu.tr/course/view.php?id=20035)
  â†’ Gerekli bilgiler iÃ§in dersteki PDFâ€™ler kullanÄ±ldÄ±.
