# 🎶 Song Lyrics NLP Project

Bu proje, İngilizce şarkı sözleri üzerinden doğal dil işleme (NLP) yöntemleri kullanarak **öneri sistemleri** geliştirmeyi ve **TF-IDF** ile **Word2Vec** tekniklerinin performansını karşılaştırmayı amaçlamaktadır. Metin verileri temizlendikten sonra vektörleştirilerek anlamsal benzerlik analizleri yapılmıştır.

---

## 📊 Veri Seti Hakkında

Bu projede kullanılan ham veri, farklı tür ve sanatçılardan derlenmiş **55.000+** şarkı sözü satırı içerir. Temizleme ve ön işleme sürecinden geçirilerek iki ayrı versiyon oluşturulmuştur:

| Özellik           | Açıklama                                                               |
| ----------------- | ---------------------------------------------------------------------- |
| 🎵 Satır Sayısı   | Yaklaşık **55.650** şarkı sözü                                         |
| 📂 İçerik         | Her satırda bir şarkı sözü; `artist`, `song`, `cleaned_text` sütunları |
| 📄 Dosya Formatı  | CSV (`.csv`)                                                           |
| ✨ Versiyonlama    | `cleaned_lemmatized.csv` ve `cleaned_stemmed.csv`                      |
| 🛠️ Ön İşleme     | Noktalama, rakam, özel karakter temizliği + lemmetizasyon & stemming   |
| 🔍 Kullanım Amacı | TF-IDF, Word2Vec (embedding) analizleri                                |

> **Not:** Veri seti kamuya açık değildir; akademik çalışma amacıyla sınırlı kullanılmıştır.

---

## ⚙️ Kurulum

Aşağıdaki adımları izleyerek projeyi çalıştırabilirsiniz:

1. **Repoyu klonlayın**

   ```bash
   git clone https://github.com/muhmmdrncbr/song-lyrics-nlp
   cd sarki-onerici
   ```
2. **Sanal ortam oluşturun ve aktif edin**

   ```bash
   python -m venv venv
   source venv/bin/activate   # macOS/Linux
   venv\\Scripts\\activate # Windows
   ```
3. **Gerekli paketleri yükleyin**

   ```bash
   pip install -r requirements.txt
   ```

---

## ▶️ Nasıl Çalıştırılır

1. **Jupyter Notebook** sunucusunu başlatın:

   ```bash
   jupyter notebook
   ```
2. `notebooks/final2_odev_song_recommender.ipynb` dosyasını açın.
3. Hücreleri sırayla çalıştırarak analizleri ve sonuçları inceleyin.
4. **Sonuçlar ve Grafikler** otomatik olarak `results/` ve `figures/` klasörlerine kaydedilecektir.

> **Öneri:** Tek satırda HTML raporu oluşturmak için:
>
> ```bash
> jupyter nbconvert --to html --execute notebooks/final2_odev_song_recommender.ipynb --output figures/rapor.html
> ```

---

## 📁 Proje Klasör Yapısı

```text
├── results/              # Benzerlik sonuçları (CSV)

```

---

## 📈 Sonuçlar ve Değerlendirme

Bu bölümde, proje süresince elde edilen başlıca bulgular özetlenmekte ve modeller arası performans karşılaştırılması sunulmaktadır.

### 🔹 TF-IDF Modelleri

* **Ortalama Cosine Similarity (Top‑5)**: 0.56 – 0.66 aralığında yoğunlaştı.
* **Ortalama Semantic Score**: 1.5 – 2.0 aralığında, anlamsal yeterliliğin düşük olduğunu gösterdi.
* **Jaccard Tutarlılığı**: Lemmatized ve Stemmed versiyonlar arasında J ≈ 0.67; model varyasyonları arasında yüksek örtüşme, ancak bağlamsal anlam kaybı.
* **Genel Değerlendirme**: TF-IDF, hızlı ve düşük kaynak tüketimli ortamlarda temel kelime benzerlikleri için uygun. Ancak, içerik derinliği ve anlamsal tutarlılık gerektiren uygulamalarda yetersiz kalmaktadır.

### 🔹 Word2Vec Modelleri

* **En Yüksek Cosine Similarity**: Skip‑Gram + HS (w=10) modelinde 0.96’nın üzerine çıktı.
* **Ortalama Semantic Score**: 4.2 – 4.8 aralığında yüksek anlamsal doğruluk.
* **Parametre Etkisi**:

  * **Skip‑Gram (sg=1)** modelleri, CBOW’a göre %20–30 daha yüksek semantic skorlar sağladı.
  * **Hierarchical Softmax (hs=1)** ile özellikle Skip‑Gram kombinasyonu, öneri kalitesini belirgin biçimde artırdı.
  * **Pencere Boyutu (w=5 vs w=10)**, küçük boyutta dahi tutarlı bağlam öğrenmeyi sürdürdü.
* **Jaccard Tutarlılığı**:

  * Aynı aile içi varyasyonlarda J değerleri 0.43 – 0.67 aralığında. Parametre değişimi öneri listesini önemli ölçüde çeşitlendirdi.
  * TF‑IDF modelleriyle örtüşme neredeyse sıfır; tamamen farklı öneri setleri.

### 🔹 Karşılaştırmalı Analiz

| Model              | Avg Similarity | Avg Semantic Score |      Jaccard (En yakın)     |
| ------------------ | :------------: | :----------------: | :-------------------------: |
| TF-IDF Lemmatized  |      0.61      |         1.7        |       vs Stemmed: 0.67      |
| TF-IDF Stemmed     |      0.63      |         1.8        |     vs Lemmatized: 0.67     |
| w2v\_sg1\_hs1\_w10 |      0.96      |         4.8        | vs w2v\_sg1\_hs0\_w10: 0.60 |
| w2v\_sg1\_hs0\_w5  |      0.95      |         4.6        |  vs w2v\_sg1\_hs1\_w5: 0.57 |

### 🔹 Öneriler

1. **Yüksek Doğruluk Gerektiren Uygulamalar**: Skip‑Gram + HS (w=10) Word2Vec modeli tercih edilmeli.
2. **Kaynak ve Hız Öncelikli Senaryolar**: TF‑IDF ile hızlı ön filtreleme, ardından Word2Vec tabanlı derinlemesine analiz önerilir.
3. **Hibrit Yaklaşımlar**: TF‑IDF ile olası adayları daraltıp, Word2Vec ile anlamsal seçki yapmak performansı ve doğruluğu birlikte optimize eder.

## 📚 Kaynakça

* Salton, G. & McGill, M. J. (1983). *Introduction to Modern Information Retrieval*.
* Mikolov, T. et al. (2013). *Efficient Estimation of Word Representations in Vector Space*.
* Pedregosa, F. et al. (2011). *Scikit-learn: Machine Learning in Python*.
* Rehurek, R. & Sojka, P. (2010). *Software Framework for Topic Modelling with Large Corpora*.
* Hunter, J. D. (2007). *Matplotlib: A 2D Graphics Environment*.
